{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31f9d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "from pytorch_toolbelt.inference import tta\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9fcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=True)\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.fc = nn.Linear(in_features, cls)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7eee927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def inference(model, img_path):\n",
    "    \n",
    "    ## preprocessing\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255\n",
    "    img= img.astype(np.float32)\n",
    "    aug= get_test_transform(CFG['img_size'])\n",
    "    img= aug(image= img)[\"image\"].cuda()\n",
    "    img= torch.unsqueeze(img, 0)\n",
    "    \n",
    "    for i, m in enumerate(model):\n",
    "        with torch.no_grad():\n",
    "            m.eval()\n",
    "            if CFG['TTA']:\n",
    "                pred= tta.fliplr_image2label(m, img)[0]\n",
    "            else:\n",
    "                pred= m(img)[0]\n",
    "                \n",
    "        if i==0: preds= pred\n",
    "        else: preds+= pred\n",
    "            \n",
    "    pred= preds/len(model)\n",
    "    pred_prob= pred.softmax(dim=-1).cpu().numpy()\n",
    "    pred= pred.softmax(dim=-1).cpu().argmax(0).numpy()\n",
    "    return pred, pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4c20b",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3754a6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of model: 3\n"
     ]
    }
   ],
   "source": [
    "CFG= {\n",
    "    'img_size': int(448*1.1),\n",
    "    'TTA': True,\n",
    "    'model_path': './Model/test/effb4_448',\n",
    "    'model': None,\n",
    "}\n",
    "CFG['model']= [ torch.load(m, map_location= 'cuda:0') for m in glob.glob(CFG['model_path']+'/**')]\n",
    "print(f\"length of model: {len(CFG['model'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f00e4",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6563c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset: 20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/test_img_512\\test_0\\0005479429a4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/test_img_512\\test_0\\0006849c44f2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/test_img_512\\test_0\\0006fcc93fc9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/test_img_512\\test_0\\00088803914c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/test_img_512\\test_0\\000b572940a1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image_path\n",
       "0  Dataset/test_img_512\\test_0\\0005479429a4.jpg\n",
       "1  Dataset/test_img_512\\test_0\\0006849c44f2.jpg\n",
       "2  Dataset/test_img_512\\test_0\\0006fcc93fc9.jpg\n",
       "3  Dataset/test_img_512\\test_0\\00088803914c.jpg\n",
       "4  Dataset/test_img_512\\test_0\\000b572940a1.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df= pd.DataFrame(columns= ('image_path',))\n",
    "test_df['image_path']= glob.glob('Dataset/test_img_512/**/*jpg', recursive=True)\n",
    "print(f'test dataset: {len(test_df)}')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5105991",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_num']= None\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    img_path= test_df.loc[i, 'image_path']\n",
    "    pred, pred_prob= inference(CFG['model'], img_path)\n",
    "    test_df.loc[i, 'pred_num']= pred\n",
    "test_df.to_csv(f\"submission/{CFG['model_path'].split('/')[-1]}.csv\", index= False)\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
