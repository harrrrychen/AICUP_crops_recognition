{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab1420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ceec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=True)\n",
    "        \n",
    "#         in_features = self.model.classifier.in_features\n",
    "#         self.model.classifier = nn.Identity()\n",
    "        \n",
    "        in_features = self.model.head.in_features\n",
    "        self.model.head = nn.Identity()\n",
    "        \n",
    "        self.fc = nn.Linear(in_features, cls)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8881b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        \n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Blur(blur_limit= 3, p=0.3),\n",
    "        A.GaussNoise(p=0.3),\n",
    "#         A.OneOf([\n",
    "#             A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "#             A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "#         ], p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.15, rotate_limit= 30,\n",
    "                                        interpolation=cv2.INTER_LINEAR, border_mode=0, p=0.7),\n",
    "        \n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "def get_2s_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a153977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.image_path = df['image_path'].values\n",
    "        self.labels = df['class_num'].values\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.image_path[index]\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = int(self.labels[index])\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e62a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_loss(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        self.CrossEntropy= nn.CrossEntropyLoss()\n",
    "        self.SoftCrossEntropy= L.SoftCrossEntropyLoss(smooth_factor= 0.2)\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss= self.SoftCrossEntropy(y_pred, y_true)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f51ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, criterion, optimizer):\n",
    "    scaler= amp.GradScaler()\n",
    "    model.train()\n",
    "\n",
    "    ep_loss= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        \n",
    "        with amp.autocast():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "            loss/= CFG['gradient_accumulation']\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i+1) % CFG['gradient_accumulation']== 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "    return np.mean(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efbece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WP(all_pred, all_label):\n",
    "    df= pd.DataFrame(columns= ('class', 'recall', 'precision', 'f1_score'))\n",
    "    WP= 0\n",
    "    for cls in range(1, 16):\n",
    "        recall= all_pred[all_label==cls].tolist().count(cls) / all_label.tolist().count(cls)\n",
    "        precision= all_label[all_pred==cls].tolist().count(cls) / all_pred.tolist().count(cls)\n",
    "        f1_score= (2 * precision * recall) / (precision + recall)\n",
    "        WP+= precision*all_label.tolist().count(cls)\n",
    "        df.loc[cls-1]= [int(cls), round(recall,3), round(precision,3), round(f1_score,3)]\n",
    "    WP/= len(all_label)\n",
    "    display(df)\n",
    "    print(f'WP= {WP}')\n",
    "    return WP\n",
    "\n",
    "\n",
    "def valid_epoch(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    ep_loss= []\n",
    "    all_pred= []\n",
    "    all_label= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        all_label.extend(labels.cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "        all_pred.extend(preds.cpu().softmax(dim=-1).numpy().argmax(1))\n",
    "        \n",
    "    ## metrice\n",
    "    wp= WP(np.array(all_pred), np.array(all_label))\n",
    "    \n",
    "    return np.mean(ep_loss), wp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bde5f",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d8029a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'fold': 0,\n",
    "    'epoch': 10,\n",
    "    'model_name': 'swin_base_patch4_window12_384',\n",
    "    'finetune': False,\n",
    "    \n",
    "    'img_size': 384,\n",
    "    'batch_size': 8,\n",
    "    'gradient_accumulation': 1,\n",
    "    \n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 0,\n",
    "    \n",
    "    'num_classes': 16,\n",
    "    'load_model': False,\n",
    "    'save_model': './Model/train'\n",
    "}\n",
    "\n",
    "if CFG['finetune']:\n",
    "    print('finetune model')\n",
    "    CFG['load_model']= f\"Model/train/cv{CFG['fold']}_best.pth\"\n",
    "    CFG['epoch']= 5\n",
    "    CFG['lr']= 5e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa7835",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0010c7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 64216\n",
      "valid dataset: 16054\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/train_img\\banana-013\\banana\\160107-3-0...</td>\n",
       "      <td>banana</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/train_img\\banana-013\\banana\\160107-3-0...</td>\n",
       "      <td>banana</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/train_img\\banana-013\\banana\\160107-3-0...</td>\n",
       "      <td>banana</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/train_img\\banana-013\\banana\\160107-3-0...</td>\n",
       "      <td>banana</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/train_img\\banana-013\\banana\\160107-3-0...</td>\n",
       "      <td>banana</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path   class  class_num  fold\n",
       "0  Dataset/train_img\\banana-013\\banana\\160107-3-0...  banana         13     2\n",
       "1  Dataset/train_img\\banana-013\\banana\\160107-3-0...  banana         13     2\n",
       "2  Dataset/train_img\\banana-013\\banana\\160107-3-0...  banana         13     0\n",
       "3  Dataset/train_img\\banana-013\\banana\\160107-3-0...  banana         13     0\n",
       "4  Dataset/train_img\\banana-013\\banana\\160107-3-0...  banana         13     3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Dataset/train.csv')\n",
    "train_df= df[df['fold']!=CFG['fold']]\n",
    "valid_df= df[df['fold']==CFG['fold']]\n",
    "print(f'train dataset: {len(train_df)}')\n",
    "print(f'valid dataset: {len(valid_df)}')\n",
    "\n",
    "train_df= pd.concat([train_df, valid_df],axis=0)\n",
    "if CFG['finetune']:\n",
    "    train_dataset= Customize_Dataset(train_df, get_2s_train_transform(CFG['img_size']))\n",
    "else:\n",
    "    train_dataset= Customize_Dataset(train_df, get_train_transform(CFG['img_size']))\n",
    "valid_dataset= Customize_Dataset(valid_df, get_test_transform(CFG['img_size']))\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size= CFG['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8144c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46fc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create model\n",
    "if CFG['load_model']:\n",
    "    print(f\"load_model: {CFG['load_model']}\")\n",
    "    model= torch.load(CFG['load_model'], map_location= 'cuda')\n",
    "else:\n",
    "    model= Customize_Model(CFG['model_name'], CFG['num_classes'])\n",
    "model.to('cuda')\n",
    "    \n",
    "## hyperparameter\n",
    "criterion= Customize_loss()\n",
    "optimizer= optim.AdamW(model.parameters(), lr= CFG['lr'], weight_decay= CFG['weight_decay'])\n",
    "\n",
    "## start training\n",
    "best_score= 0\n",
    "for ep in range(1, CFG['epoch']+1):\n",
    "    print(f'ep: {ep}')\n",
    "    \n",
    "    train_loss= train_epoch(train_loader, model, criterion, optimizer)\n",
    "    valid_loss, valid_acc= valid_epoch(valid_loader, model, criterion)\n",
    "    print(f'train loss: {train_loss}')\n",
    "    print(f'valid loss: {valid_loss}')\n",
    "    \n",
    "    if valid_acc >= best_score:\n",
    "        best_score= valid_acc\n",
    "        torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_swin_best.pth\")\n",
    "        print(f'model save at score: {best_score}')\n",
    "        \n",
    "    ## save model every epoch\n",
    "    torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_ep{ep}.pth\")\n",
    "    \n",
    "    ## adjust lr\n",
    "    if ep == 7:\n",
    "        model= torch.load(f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\")\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease learning rate to 1e-4!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
